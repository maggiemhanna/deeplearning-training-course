{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Classification of RNN Models\n",
    "\n",
    "By now, I‚Äôm sure, you must have understood the fundamentals of Recurrent Neural Networks, their basic architecture, and the computational representation of RNN‚Äôs forward and backpropagation techniques.\n",
    "\n",
    "The one major point we have been discussing since our previous post is that in our basic RNN models, we have, so far, considered the input and output sequences to be of equal lengths. While we started off with equal lengths for the sake of ease of understanding concepts, we must now venture into the various other possibilities that may arise in real-life scenarios and problems.\n",
    "\n",
    "To classify in the most simplistic manner, we can categorize RNN architectures broadly into these four buckets:\n",
    "\n",
    "* Many Inputs √≥ Many Outputs\n",
    "* Many Inputs √≥ One Output\n",
    "* One Input √≥ One Output\n",
    "* One Input √≥ Many Outputs\n",
    "\n",
    "Going ahead in this blog post, we will learn about the above four categories in detail, with some explanatory examples. So, let‚Äôs get going."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Applications of RNN in Real-Life Scenarios\n",
    "\n",
    "Up until now, we have come across RNN architectures where the number of inputs x is equal to the number of outputs y. Let‚Äôs revise our list of some practical examples we saw in an earlier post and understand how RNN architectures differ in each case.\n",
    "\n",
    "<img src=\"figures/applications.jpg\" width=\"700px\">\n",
    "\n",
    "Up It is not necessary that we will always find ourselves in an ideal scenario where the input x and output y are of the same type, and $T_x$ and $T_y$ will be equal.\n",
    "\n",
    "Take, for example, Music Generation. Here, the length of input $T_x$ can be 1 or it may well be an empty set. In the case of Sentiment Classification, the output ùë¶ ranges from integral values of 1 to 5. Observe how Name Entity Recognition is our original scenario where the length of both input and output is the same. Having said that, there are some problems with the Name Entity Recognition where the input-output lengths can be different as well. Looking at the case of Machine Translation, both input and output sequence can have varying lengths since the input is say, a French sentence and the output is the translated English sentence. The meaning, no doubt, is the same but the length of the sequences is different.\n",
    "\n",
    "Such are the possibilities that can arise in the case of RNN architectures, however, there are established ways that define how to tackle these cases by modifying the basic RNN architecture.\n",
    "\n",
    "Note: Some of the figures and facts from this particular post have taken inspiration from another blog post by Andre Coffee which is titled ‚ÄúUnreasonable effectiveness of recurrent neural networks‚Äù.\n",
    "\n",
    "Let us go one by one in understanding the four major categories of RNN architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Many-to-Many Architecture\n",
    "\n",
    "Well, this one is easy because we have seen this before. This is exactly what we learned in our previous posts. A Recurrent Neural Network where the input and output lengths are equal $T_x = T_y$.\n",
    "\n",
    "<img src=\"figures/many_to_many.jpg\" width=\"600px\">\n",
    "\n",
    "\n",
    "The input sequence starts from $x^{‚ü®1‚ü©}$, $x^{‚ü®2‚ü©}$ up to $x^{‚ü®T_x‚ü©}$ and the output sequence computed is $\\hat{y}^{‚ü®1‚ü©}$, $\\hat{y}^{‚ü®2‚ü©}$ and so on up to $\\hat{y}^{‚ü®T_y‚ü©}$. Since there are multiple inputs which result in multiple outputs, we can call it a Many-to-Many architecture.\n",
    "\n",
    "In the above example, the input and the output sequence lengths are equal. However, within Many-to-Many architectures, there are examples where these input and output lengths are different. Machine Translation is one such real-life case where the input sentence says, in French, and the output sentence is a translated English one, which may have a different number of words than the original sentence but of course, the meaning remains the same.\n",
    "\n",
    "Such neural networks have two distinct portions ‚Äì the Encoder and the Decoder. The Encoder is what takes the input in French and the Decoder is where the sentence is read and translated into a different language.\n",
    "\n",
    "<img src=\"figures/machine_translation_2.jpg\" width=\"600px\">\n",
    "\n",
    "\n",
    "Now, let us look at another example where the inputs are many but the output is singular.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Many-to-One Architecture\n",
    "\n",
    "We will take the case of Sentiment Classification to explain this category of RNN models where there are multiple inputs but only one output value.\n",
    "\n",
    "<img src=\"figures/many_one.jpg\" width=\"600px\">\n",
    "\n",
    "In our example for Sentiment Classification, we learned how movie reviews can be turned into a star rating. Here, the input ùë• is a piece of movie review text which says ‚ÄúDecent effort. The plot could have been better.‚Äù Hence, the input is a sequence of multiple word inputs. Now, we could predict output ùë¶ in two ways ‚Äì one, using only 0 and 1 as output values categorizing the movie review as either Positive or Negative. And, second, using values from 1 to 5 in which case our example would qualify as neither a bad nor an excellent review, but a mixed review. Thus, the output value will be something like 3 stars. This is what we call Many-to-One architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. One-to-One Architecture\n",
    "\n",
    "This one is as basic as it gets. A single input that predicts a single output forms what we call a One-to-One architecture. It is the most standard Neural Network there can be and is quite self-explanatory. An important thing to note in One-to-One architectures is that you don‚Äôt really need an activation value $a$, incoming or outgoing, as this is a very simple scenario of Input IN and output OUT.\n",
    "\n",
    "\n",
    "<img src=\"figures/one_one.jpg\" width=\"100px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. One-to-Many Architecture\n",
    "\n",
    "A single input that results in multiple output values or an output sequence is called a One-to-Many architecture. This particular architecture can be found in the Music Generation problems.\n",
    "\n",
    "<img src=\"figures/one_many.jpg\" width=\"600px\">\n",
    "\n",
    "Say, you are given an integral input ùë•, which tells the network what genre of music you want, or the first note of the music that you like. It can even be a null input ùë• where you don‚Äôt feed anything and want the network to randomly generate some music, in which case the input ùë• will just be a vector of zeros. In such cases, once the input ùë• is fed into the neural network, no other input is given for the entire propagation process. Only the activation values that predict outputs at each time step and multiple outputs predicted are received until the last note of the musical piece is synthesized.\n",
    "\n",
    "Let us summarise all the categories of RNN architectures we learned so far in a compiled graphical format. Have a look.\n",
    "\n",
    "<img src=\"figures/all.jpg\" width=\"900px\">\n",
    "\n",
    "Notice how each category of RNN architecture differs in execution from the other. These are the basic building blocks of all Recurrent Neural Networks that exist, apart from some subtle variations in sequence generation, which we will learn in the due course of time.\n",
    "\n",
    "We can create a wide range of RNN models using the above categorization of RNNs. I hope you will research more real-life examples of these four types of RNN architectures. Do write your comments below citing more cases, especially where input and output sequences are of varying lengths. In the upcoming posts, we will learn more about sequence generation, implementing a Language Model, and how to sample novel sequences, among much more interesting information. So, stay tuned!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architectural Classification of Recurrent Neural Networks\n",
    "\n",
    "* Basic categorization based on input and output quantities\n",
    "* Four main types of RNNs ‚Äì Many-to-Many, Many-to-One, One-to-One, and One-to-Many\n",
    "* Not all types of RNNs have input and output sequences with equal lengths\n",
    "* Machine Translation is a Many-to-Many architecture\n",
    "* Sentiment Classification is a Many-to-One architecture\n",
    "* Music Generation is a One-to-Many architecture\n",
    "* One-to-One architecture is the most standard form of neural network\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
