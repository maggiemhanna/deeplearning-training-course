{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Maximum likelihood estimation (MLE)\n",
    "\n",
    "## 1.1. Likelihood function\n",
    "\n",
    "In statistics, the likelihood function (often simply called the likelihood) measures the goodness of fit of a statistical model to a sample of data $\\boldsymbol{\\mathscr{X}} = (\\mathbf{x}^{(1)}, \\mathbf{x}^{(2)}, ..., \\mathbf{x}^{(m)})$ for given values of the unknown parameters of the statistical model.\n",
    "\n",
    "Let ${\\displaystyle \\boldsymbol{\\mathsf{X}}}$ be a discrete random variable modeled using probability density function ${\\displaystyle p_{\\boldsymbol{\\theta}}}$ depending on the vector of parameters ${\\displaystyle \\boldsymbol{\\theta}}$. Then the function\n",
    "\n",
    "\\begin{equation}\n",
    "{\\displaystyle \\mathcal{L}(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\mathscr{X}}):\\boldsymbol{\\theta} \\mapsto p_{\\boldsymbol{\\theta}}(\\boldsymbol{\\mathscr{X}})=P_{\\boldsymbol{\\theta}}(\\boldsymbol{\\mathsf{X}}^m=\\boldsymbol{\\mathscr{X}} )}\n",
    "\\end{equation}\n",
    "\n",
    "considered as a function of $\\boldsymbol{\\theta}$, is the likelihood function, given the sample outcome $\\boldsymbol{\\mathscr{X}} = (\\mathbf{x}^{(1)}, \\mathbf{x}^{(2)}, ..., \\mathbf{x}^{(m)})$ of the random variable ${\\displaystyle \\boldsymbol{\\mathsf{X}}}$. \n",
    "\n",
    "The likelihood ${\\displaystyle {\\mathcal {L}}(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\mathscr{X}})}$ is equal to the probability that the particular outcome $\\boldsymbol{\\mathscr{X}}$ is observed when the true value of the parameter is $\\boldsymbol{\\theta}$.\n",
    "\n",
    "To summarize:\n",
    "\n",
    "* For a sample of data $\\boldsymbol{\\mathscr{X}} = (\\mathbf{x}^{(1)}, \\mathbf{x}^{(2)}, ..., \\mathbf{x}^{(m)})$\n",
    "* We fit a statistical model $p_{\\boldsymbol{\\theta}}$\n",
    "* The likelihood function ${\\displaystyle {\\mathcal {L}}(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\mathscr{X}}):\\boldsymbol{\\theta}\\mapsto P_{\\boldsymbol{\\theta}}(\\boldsymbol{\\mathsf{X}}^m=\\boldsymbol{\\mathscr{X}})}$ is then the goodness of fit of the statistical model $p_{\\boldsymbol{\\theta}}$.\n",
    "* $p_{\\boldsymbol{\\theta}}(\\boldsymbol{\\mathscr{X}})$ is the probability that this particular outcome $\\boldsymbol{\\mathscr{X}}$ is observed under the statistical model $p_{\\boldsymbol{\\theta}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Maximum likelihood estimation\n",
    "\n",
    "In statistics, maximum likelihood estimation (MLE) is a method of estimating the parameters of a probability distribution by maximizing a likelihood function, so that under the assumed statistical model the observed data is most probable. The point in the parameter space that maximizes the likelihood function is called the maximum likelihood estimate.\n",
    "\n",
    "From a statistical standpoint, a given set of observations are a random sample from an unknown population. The goal of maximum likelihood estimation is to make inferences about the population that is most likely to have generated the sample, specifically the joint probability distribution of the random variables ${\\displaystyle \\left\\{\\mathbf{x}^{(1)},\\mathbf{x}^{(2)},\\ldots \\right\\}}$. Associated with each probability distribution is a unique unique vector ${\\displaystyle \\boldsymbol{\\theta} =\\left[\\theta _{0},\\,\\theta _{1},\\ldots \\,,\\theta _{n}\\right]^{\\mathsf {T}}}$ of parameters that index the probability distribution within a parametric family ${\\displaystyle \\{f(\\cdot \\,;\\boldsymbol{\\theta} )\\mid \\boldsymbol{\\theta} \\in \\Phi \\}}$, where ${\\displaystyle \\Phi }$  is called the parameter space, a finite-dimensional subset of Euclidean space. Evaluating the joint density at the observed data sample $\\boldsymbol{\\mathscr{X}} = (\\mathbf{x}^{(1)}, \\mathbf{x}^{(2)}, ..., \\mathbf{x}^{(m)})$ gives a real-valued function $f_{m}(\\boldsymbol{\\mathscr{X}}; \\boldsymbol{\\theta})$.\n",
    "\n",
    "The goal of maximum likelihood estimation is to find the values of the model parameters that maximize the likelihood function over the parameter space, that is\n",
    "\n",
    "$$\n",
    "{\\displaystyle {\\hat {\\boldsymbol{\\theta}}}={\\underset {\\boldsymbol{\\theta} \\in \\Phi }{\\operatorname {arg\\;max} }}\\ {\\widehat{\\mathcal{L}}}(\\boldsymbol{\\theta} \\,\\mid\\boldsymbol{\\mathscr{X}}) = {\\underset {\\boldsymbol{\\theta} \\in \\Phi }{\\operatorname {arg\\;max} }} \\displaystyle f_{m}(\\boldsymbol{\\mathscr{X}} ;\\boldsymbol{\\theta})}\n",
    "$$\n",
    "\n",
    "For independent and identically distributed random variables, ${\\displaystyle f_{m}(\\boldsymbol{\\mathscr{X}} ;\\boldsymbol{\\theta})}$ will be the product of univariate density functions.\n",
    "\n",
    "$$\n",
    "{\\displaystyle {\\hat {\\boldsymbol{\\theta} }} = {\\underset {\\boldsymbol{\\theta} \\in \\Phi }{\\operatorname {arg\\;max} }} \\prod_{i=1}^{m} f({\\mathbf{x}}^{(i)} ;\\boldsymbol{\\theta})}\n",
    "$$\n",
    "\n",
    "Intuitively, this selects the parameter values that make the observed data most probable. The specific value ${\\displaystyle {\\hat {\\boldsymbol{\\theta} }} \\in \\Phi }$ that maximizes the likelihood function ${\\displaystyle \\mathcal{L}}$ is called the maximum likelihood estimate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Likelihood of a logestic regression model\n",
    "\n",
    "In the context of classification, the likelihood function measures how well a model fits the data. Suppose we have a dataset $\\boldsymbol{\\mathscr{X}}$ consisting of $m$ datapoints and $n$ features. The class variable $\\boldsymbol{\\mathscr{y}}$ is a vector of length $m$ which can have two values $1$ or $0$. Under the classification model, the probability of the class variable value $y^{(i)}=1$ , $i=1,2,...,m$ can be modelled as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "p(y^{(i)}=1|\\mathbf{x}^{(i)};\\boldsymbol{\\theta}) = h_{\\boldsymbol{\\theta}}(\\mathbf{x}^{(i)})\n",
    "\\end{equation}\n",
    "\n",
    "So $y^{(i)}=1$ with probability $h_{\\boldsymbol{\\theta}}(\\mathbf{x}^{(i)})$ and $y^{(i)}=0$ with probability $1-h_{\\boldsymbol{\\theta}}(\\mathbf{x}^{(i)})$. This can be combined into a single equation as follows, (actually $y^{(i)}$ follows a **Bernoulli** distribution):\n",
    "\n",
    "\\begin{equation}\n",
    "p(y^{(i)}|\\mathbf{x}^{(i)};\\boldsymbol{\\theta}) = h_{\\boldsymbol{\\theta}}(\\mathbf{x}^{(i)})^{y^{(i)}}(1-h_{\\boldsymbol{\\theta}}(\\mathbf{x}^{(i)}))^{1-y^{(i)}}\n",
    "\\end{equation}\n",
    "\n",
    "This is also the likelihood of single data point $\\mathbf{x}^{(i)}$, i.e. the probability of $\\mathbf{x}^{(i)}$ occurring given the value of $y^{(i)}$ under the assumption of our model $p_{\\boldsymbol{\\theta}}$. It is the conditional probability $p_{\\boldsymbol{\\theta}}(\\mathbf{x}^{(i)}|y^{(i)})$.\n",
    "\n",
    "Given that the data points are independently and identically distributed, the likelihood of the entire dataset $\\boldsymbol{\\mathscr{X}}$ is the product of the individual data point likelihoods. Thus,\n",
    "\n",
    "$$\n",
    "{\\mathcal {L}}(\\boldsymbol{\\theta}) = P(\\boldsymbol{\\mathscr{X}}|\\boldsymbol{\\mathscr{y}}) = \\prod_{i=1}^{m} p(\\mathbf{x}^{(i)} | y^{(i)}) = \\prod_{i=1}^{m} h_{\\boldsymbol{\\theta}}(\\mathbf{x}^{(i)})^{y^{(i)}} (1 - h_{\\boldsymbol{\\theta}}(\\mathbf{x}^{(i)}))^{1-y^{(i)}}\n",
    "$$\n",
    "\n",
    "Now the principle of maximum likelihood, the optimal parameters $\\boldsymbol{\\theta}$ of our model can be found by maximizing likelihood $P(\\boldsymbol{\\mathscr{X}}|\\boldsymbol{\\mathscr{y}})$. Logarithms are used because they convert products into sums (easier to manipulate) and do not alter the maximization search, as they are monotone increasing functions. Here too we have a product form in the likelihood. We take the natural logarithm as maximising the likelihood is same as maximizing the log likelihood, so log likelihood ${\\mathcal{L}}(\\theta)$ is now:\n",
    "\n",
    "$$\n",
    "\\log {\\mathcal {L}}(\\boldsymbol{\\theta}) = \\log P(\\boldsymbol{\\mathscr{X}}|\\boldsymbol{\\mathscr{y}}) =  \\sum_{i=1}^{m} y^{(i)} \\log(h_{\\boldsymbol{\\theta}}(\\mathbf{x}^{(i)})) + (1-y^{(i)}) \\log(1 - h_{\\boldsymbol{\\theta}}(\\mathbf{x}^{(i)}))\n",
    "$$\n",
    "\n",
    "In linear regression we found the $\\theta$ that minimizes our cost function, here too for the sake of consistency, we would like to have a minimization problem. And we want the average cost over all the data points. Currently, we have a maximimzation of ${\\mathcal {L}}(\\theta)$. Maximization of ${\\mathcal {L}}(\\theta)$ is equivalent to minimization of −${\\mathcal {L}}(\\theta)$. And using the average cost over all data points, our cost function for logistic regresion comes out to be:\n",
    "\n",
    "$$\n",
    "J(\\boldsymbol{\\theta}) = - \\dfrac{1}{m} \\log \\mathcal{L}(\\boldsymbol{\\theta})\n",
    "$$\n",
    "\n",
    "$$\n",
    "= - \\dfrac{1}{m} \\left(  \\sum_{i=1}^{m} y^{(i)} \\log (h_{\\boldsymbol{\\theta}}(\\mathbf{x}^{(i)})) +  (1-y^{(i)}) \\log (1 - h_{\\boldsymbol{\\theta}}(\\mathbf{x}^{(i)})) \\right )\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Cross-Entropy\n",
    "\n",
    "## 2.1. Entropy\n",
    "\n",
    "The information entropy is a basic quantity in information theory associated to any random variable, which can be interpreted as the average level of \"information\", \"surprise\", or \"uncertainty\" inherent in the variable's possible outcomes. Entropy can be seen as the amount of information (for example **number of bits**) required to transmit a randomly selected event from a probability distribution. The more number of bits you need, the more uncertainty/information there are. A skewed distribution has a low entropy, whereas a distribution where events have equal probability has a larger entropy.\n",
    "\n",
    "Shannon defined the entropy $H$ of a discrete random variable ${\\textstyle Y}$ with possible values ${\\textstyle \\left\\{y_{1},\\ldots ,y_{C}\\right\\}}$ and probability mass function ${\\textstyle \\mathrm{q}(y)}$ as:\n",
    "\n",
    "$$\n",
    "{\\displaystyle \\mathrm {H} (y)=\\operatorname {\\mathbb{E}} [\\operatorname {I} (y)]=\\operatorname {\\mathbb{E}} [-\\log(\\mathrm {q} (y))].}\n",
    "$$\n",
    "\n",
    "Here ${\\displaystyle \\operatorname {\\mathbb{E}} }$ is the expected value operator, and $I$ is the information content of $y$. ${\\displaystyle I(y)}$ is itself a random variable.\n",
    "\n",
    "The entropy can explicitly be written as:\n",
    "\n",
    "$$\n",
    "{\\displaystyle \\mathrm {H} (y)=-\\sum _{i=1}^{C}{\\mathrm {q} (y_{c})\\log _{b}\\mathrm {q} (y_{c})}}\n",
    "$$\n",
    "\n",
    "where b is the base of the logarithm used. Common values of b are 2, Euler's number e, and 10, and the corresponding units of entropy are the bits for b = 2, nats for b = e, and bans for b = 10.\n",
    "\n",
    "In the case of $q(y_i) = 0$ for some i, the value of the corresponding summand $0 log_b(0)$ is taken to be 0, which is consistent with the limit ${\\displaystyle \\lim _{q\\to 0^{+}}q\\log(q)=0}$.\n",
    "\n",
    "#### Example\n",
    "\n",
    "Let's assume we have a set of observations of 2 models of cars: BMW and AUDI. These are our labels. This can be modelled as a Bernoulli process of probabilities $(p, 1-p)$.\n",
    "\n",
    "What if all of our observations were BMW? What would be the uncertainty of that distribution? ZERO, right? After all, there would be no doubt about the model of a car: it is always BMW! So, the entropy is zero! In this case, the probability mass distribution of $Y$ can be written as $y_{i} \\in \\{\\mathtt{BMW}\\} \\sim \\{1\\}$, the assocaited entropy can be calculated using:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathrm{H}(y) \n",
    "&= -\\sum_{i=1}^{k}{\\mathrm{q}(y_{i})\\log_{b}\\mathrm{q}(y_{i})} \\newline\n",
    "&= - \\mathrm{Pr}(\\mathtt{BMW})\\log_{2}\\mathrm{Pr}(\\mathtt{BMW}) \\newline\n",
    "&= -  (1)\\log_{2}(1) = 0\n",
    "\\end{align*}\n",
    "    \n",
    "In other words, we need **ZERO bits** to represent this random variable.\n",
    "\n",
    "On the other hand, what if we knew exactly half of the cars were BMW and the other half, AUDI? That’s the worst case scenario, right? We would have absolutely no edge on guessing the model of a car: it is totally random! This is the situation of maximum uncertainty as it is most difficult to predict the model of the next car. The probability mass distribution of $Y$ can be written as $y_{i} \\in \\{\\mathtt{BMW}, \\mathtt{AUDI}\\} \\sim \\{0.5, 0.5\\}$, the corresponding entropy is then:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathrm {H} (y) \n",
    "&= -\\sum_{i=1}^{k}{\\mathrm{q}(y_{i})\\log_{b}\\mathrm{q}(y_{i})} \\newline\n",
    "&= - \\left[\\mathrm{Pr}(\\mathtt{BMW})\\log_{2}\\mathrm{p}(\\mathtt{BMW}) + \\mathrm{Pr}(\\mathtt{AUDI})\\log_{2}\\mathrm{p}(\\mathtt{AUDI})\\right]\\newline\n",
    "&= - \\left[ (0.5)\\log_{2}(0.5) + (0.5)\\log_{2}(0.5) \\right] = 1\n",
    "\\end{align*}\n",
    "    \n",
    "We need exactly **ONE bit** to represent this random variable. \n",
    "\n",
    "The next figure shows entropy of a bernoulli(p) distribution as a function of the probability $p$:\n",
    "\n",
    "<img src=\"figures/entropy.png\" alt=\"entropy\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Cross-Entropy\n",
    "\n",
    "Cross-entropy builds upon the idea of entropy from information theory and calculates the number of bits required to represent or transmit an average event from one distribution compared to another distribution.\n",
    "\n",
    "> ... the cross entropy is the average number of bits needed to encode data coming from a source with distribution p when we use model q ... — Page 57, Machine Learning: A Probabilistic Perspective, 2012.\n",
    "\n",
    "The intuition for this definition comes if we consider a target or underlying probability distribution p and an approximation of the target distribution q, then the cross-entropy of q from p is the number of additional bits to represent an event using q instead of p.\n",
    "\n",
    "For a discrete random variable ${\\textstyle Y}$ with possible values ${\\textstyle \\left\\{y_{1},\\ldots ,y_{C}\\right\\}}$ and probability mass function ${\\textstyle \\mathrm{q}(y)}$ represented using ${\\textstyle \\mathrm{p}(y)}$, this means:\n",
    "\n",
    "$$\n",
    "{\\displaystyle H(q,p) = -\\operatorname{E}_{q}[\\log p] =- \\sum_{c=1}^{C} q(y_c)\\,\\log_b p(y_c)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Binary cross-entropy of logestic regression model \n",
    "\n",
    "Suppose we have a dataset $\\boldsymbol{\\mathscr{X}}$ consisting of $m$ datapoints and $n$ features. The class variable $\\boldsymbol{\\mathscr{y}}$ is a vector of length $m$ which can have two values $1$ or $0$.\n",
    "\n",
    "Let $q(y \\mid \\mathbf{x})$ be the real unknown distribution of our data (we can also call it **data disribution**) of our distribution modelled using $p(y \\mid \\mathbf{x}) = h_{\\theta}(\\mathbf{x})$ (**model distribution**).\n",
    "\n",
    "Logistic regression typically optimizes the loss for all the observations on which it is trained, which is the same as optimizing the average cross-entropy in the sample. For example, suppose we have ${\\displaystyle m}$ samples with each sample indexed by ${\\displaystyle i=1,\\dots ,m}$. The average of the cross-entropy is then given by:\n",
    "\n",
    "\\begin{align*}\n",
    "H(q,p) \n",
    "&= \\frac {1}{m} \\sum _{i=1}^{m} H(q_{i},p_{i}) \\newline\n",
    "&= -\\frac{1}{m}\\sum_{i=1}^{m} \\sum_{y^{(i)} \\in \\{0,1\\}} q(y^{(i)}|\\mathbf{x}_i) \\log p_{\\theta}(y^{(i)}|\\mathbf{x}_i) \\newline\n",
    "&=-\\frac{1}{m}\\sum_{i=1}^{m} \\left[ q(y^{(i)}=1|\\mathbf{x}_i) \\log p_{\\theta}(y^{(i)}=1|\\mathbf{x}_i) + q(y^{(i)}=0|\\mathbf{x}_i) \\log p_{\\theta}(y^{(i)}=0|\\mathbf{x}_i)\\right]\n",
    "\\end{align*}\n",
    "\n",
    "${q(y^{(i)}=1|\\mathbf{x}_i)={\\begin{cases}1&{\\text{if }}y^{(i)}=1,\\\\0&{\\text{if }}y^{(i)}=0.\\end{cases}}}$, then we can write $q(y^{(i)}=1|\\mathbf{x}_i) = y^{(i)}$ .\n",
    "\n",
    "${q(y^{(i)}=0|\\mathbf{x}_i)={\\begin{cases}0&{\\text{if }}y^{(i)}=1,\\\\1&{\\text{if }}y^{(i)}=0.\\end{cases}}}$, then we can write $q(y^{(i)}=0|\\mathbf{x}_i) = 1-y^{(i)}$.\n",
    "\n",
    "Therefore, the cross-entropy of our logestic model can be written as:\n",
    "\n",
    "$$\n",
    "H(q,p) = -\\frac{1}{m}\\sum_{i=1}^{m} \\left[ y^{(i)} \\log(h_{\\theta}(\\mathbf{x}_i)) + (1-y^{(i)})\\log(1-h_{\\theta}(\\mathbf{x}_i)) \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Hypothesis function\n",
    "\n",
    "In the previous sections, we explored 2 methods that allow us to define our cost function. The choice of the cost function is tightly coupled with the choice of the hypothesis function. Most of the time, we simply use cross-entropy between the data distribution and model distribution. The choice of how to represent the hypothesis function then determines the form of the cross-entropy function.\n",
    "\n",
    "Our hypothesis function needs to predict only $p_\\theta(y=1\\mid \\mathbf{x})$. For this number to be a valid probability, it must lie in the interval $[0,1]$. Satisfying this design constraints requires some careful design effort. Suppose we were to use a linear function and threshold its value to obtain a valid probability:\n",
    "\n",
    "$$\n",
    "p_\\theta(y=1 \\mid \\mathbf{x}) = \\max \\{0, \\min \\{1, \\boldsymbol{\\theta}^\\top \\mathbf{x}\\}\\}\n",
    "$$\n",
    "\n",
    "This would indeed define a valid conditional distribution, but we would not be able to train it very effectively with gradient descent. Any time $\\boldsymbol{\\theta}^\\top \\mathbf{x}$ strayed outside the unit interval, the gradient of the function of the model with respect to its parameters would be 0. A gradient of 0 is typically problematic because the learning algorithm no longer has a guide for how to improve the corresponding parameters. Instead, it is better to use a different approach that ensures there is always a strong gradient whenever the model has the wrong answer.\n",
    "\n",
    "We may proceed to define a hypothesis function that renders our loss function linear in $\\boldsymbol{\\theta}$. If we begin our assumption that the unnormalized log probabilities ($\\log \\tilde{p}$) are linear in $\\theta$. We can exponentiate to obtain the unnormalized probabilities. We then normalize to see that this yields a Bernoulli distribution controlled by a sigmoidal transformation of $\\boldsymbol{\\theta}^\\top \\mathbf{x}$\n",
    "\n",
    "Let \n",
    "\n",
    "\\begin{equation}\n",
    "\\log \\tilde{p}(y=c) = c \\ \\boldsymbol{\\theta}^\\top \\mathbf{x} \\ \\ \\ \\ \\ c \\in \\{0,1\\}\n",
    "\\end{equation}\n",
    "\n",
    "Then we can write;\n",
    "\n",
    "\\begin{align*}\n",
    "\\tilde{p}(y=c) & = e^{c \\ \\boldsymbol{\\theta}^\\top \\mathbf{x}} \\ \\ \\ \\ \\ c \\in \\{0,1\\} \\newline\n",
    "{p}(y=c) & = \\frac{e^{c \\ \\boldsymbol{\\theta}^\\top \\mathbf{x}}}{\\sum_{c^\\prime=0}^1 e^{c^\\prime \\ \\boldsymbol{\\theta}^\\top \\mathbf{x}}} \\ \\ \\ \\ \\ c \\in \\{0,1\\} \n",
    "\\end{align*}\n",
    "\n",
    "We can then assume the the class probabilities are the following:\n",
    "\n",
    "$${{p}(y=c) = {\n",
    "\\begin{cases} \n",
    "\\frac{e^{ \\boldsymbol{\\theta}^\\top \\mathbf{x}}}{1+e^{\\boldsymbol{\\theta}^\\top \\mathbf{x}}} = \\frac{1}{1+e^{-\\boldsymbol{\\theta}^\\top \\mathbf{x}}} = \\sigma(\\boldsymbol{\\theta}^\\top \\mathbf{x}) & {\\text{if }}c=1, \\\\\n",
    "\\frac{1}{1+e^{ \\boldsymbol{\\theta}^\\top \\mathbf{x}}} = \\sigma(-\\boldsymbol{\\theta}^\\top \\mathbf{x}) = 1 - \\sigma(\\boldsymbol{\\theta}^\\top \\mathbf{x}) & {\\text{if }}c=0. \n",
    "\\end{cases}}\n",
    "}\n",
    "$$\n",
    "\n",
    "$\\sigma(z)=\\frac{1}{1+e^{-z}}$ is the sigmoid function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generalizing for multinomial logistic regression\n",
    "\n",
    "Now we will approach the classification of data when we have more than two categories. Instead of y = {0,1} we will expand our definition so that $y = \\{1,2,...C\\}$. In this case, our model parameters is a 2 dimensional matrix of size ($C \\times n$), the probability of the class variable value $y^{(i)}=c$ for $c \\in \\{1, 2, ..., C\\}$, $i=1,2,...,m$ can be modelled as follows:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "p(y^{(i)}=c|\\mathbf{x}^{(i)};\\boldsymbol{\\Theta}) = h^{(c)}_{\\boldsymbol{\\Theta}}(\\mathbf{x}^{(i)}), \\ \\ \\ \\ \\ \\ \\ \\  c \\in \\{0, 1, ..., C\\}\n",
    "\\end{equation}\n",
    "\n",
    "Where the matrix of parameters $\\Theta$ can be written as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\Theta = \\left[\\begin{array}{cccc}| & | & | & | \\\\\n",
    "\\boldsymbol{\\theta}^{(1)} & \\boldsymbol{\\theta}^{(2)} & \\cdots & \\boldsymbol{\\theta}^{(C)} \\\\\n",
    "| & | & | & |\n",
    "\\end{array}\\right], \\ \\ \\ \\ \\ \\ \\ \\  \\boldsymbol{\\theta}^{(c)} = [\\theta_{1}^{(c)}, \\theta_{2}^{(c)}, ..., \\theta_{n}^{(c)}] \n",
    "\\end{equation}\n",
    "\n",
    "This is also the likelihood of single data point $\\mathbf{x}^{(i)}$ occurring given $y^{(i)}$.\n",
    "\n",
    "\\begin{equation}\n",
    "p(\\mathbf{x}^{(i)}|y^{(i)};{\\Theta}) = \\prod_{c=1}^C h_{\\Theta}^{(c)} (\\mathbf{x}^{(i)})^{\\mathbb{1}_{y^{(i)}=c}} \\ \\ \\ \\text{where} \\ \\ \\ {\\mathbb{1}_{y^{(i)}=c}={\\begin{cases}1&{\\text{if }}y^{(i)}=c,\\\\0&{\\text{if }}y^{(i)}=0.\\end{cases}}} \n",
    "\\end{equation}\n",
    "\n",
    "Given that the data points are independently and identically distributed, the likelihood of the entire dataset $\\boldsymbol{\\mathscr{X}}$ is the product of the individual data point likelihoods. Thus,\n",
    "\n",
    "$$\n",
    "{\\mathcal {L}}({\\Theta}) = P(\\boldsymbol{\\mathscr{X}}|\\boldsymbol{\\mathscr{y}}) = \\prod_{i=1}^{m} p(\\mathbf{x}^{(i)} | y^{(i)})\n",
    "$$\n",
    "\n",
    "Maximizing the log likelihood, so log likelihood ${\\mathcal{L}}(\\theta)$ is now:\n",
    "\n",
    "\\begin{align*}\n",
    "\\log {\\mathcal {L}}({\\Theta}) = \\log P(\\boldsymbol{\\mathscr{X}}|\\boldsymbol{\\mathscr{y}}) & =  \\sum_{i=1}^{m} \\log(\\prod_{c=1}^C h_{\\Theta}^{(c)}(\\mathbf{x}^{(i)}) ^ {\\mathbb{1}_{y^{(i)}=c}}) \\newline\n",
    "& =  \\sum_{i=1}^{m} \\sum_{c=1}^C {\\mathbb{1}_{y^{(i)}=c}} \\log( h_{\\Theta}^{(c)}(\\mathbf{x}^{(i)}) ) \\newline\n",
    "\\end{align*}\n",
    "\n",
    "Using the average cost over all data points, our cost function for logistic regresion comes out to be:\n",
    "\n",
    "$$\n",
    "J({\\Theta}) = - \\dfrac{1}{m} \\log \\mathcal{L}({\\Theta}) = - \\dfrac{1}{m} \\sum_{i=1}^{m} \\sum_{c=1}^C {\\mathbb{1}_{y^{(i)}=c}} \\log( h_{\\Theta}^{(c)}(\\mathbf{x}^{(i)}) ) \n",
    "$$\n",
    "\n",
    "This can also be easily obtained using a multi-class cross-entropy\n",
    "\n",
    "\\begin{align*}\n",
    "H(q,p) \n",
    "&= \\frac {1}{m} \\sum _{i=1}^{m} H(q_{i},p_{i}) \\newline\n",
    "&= -\\frac{1}{m}\\sum_{i=1}^{m} \\sum_{c =1}^C q(y^{(i)}=c|\\mathbf{x}_i) \\log p(y^{(i)}=c|\\mathbf{x}_i, \\Theta) \\newline\n",
    "&= -\\frac{1}{m}\\sum_{i=1}^{m} \\sum_{c =1}^C {\\mathbb{1}_{y^{(i)}=c}}  \\log h^{(c)}_{\\boldsymbol{\\Theta}}(\\mathbf{x}^{(i)}) \\newline\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "Similarly, we may proceed to define a hypothesis function that renders our loss function linear in $\\boldsymbol{\\theta}^{(c)}$ for all $c \\in \\{1, 2, ..., C\\}$. If we begin our assumption that the unnormalized log probability ($\\log \\tilde{p}(y=c)$) is linear in $\\boldsymbol{\\theta}^{(c)}$. We can exponentiate to obtain the unnormalized probabilities. We then normalize to obtain the softmax function.\n",
    "\n",
    "Let \n",
    "\n",
    "\\begin{equation}\n",
    "\\log \\tilde{p}(y=c) = \\boldsymbol{\\theta}^{(c)\\top} \\mathbf{x} \\ \\ \\ \\ \\ c \\in \\{1, 2,..., C\\}\n",
    "\\end{equation}\n",
    "\n",
    "Then we can write;\n",
    "\n",
    "\\begin{align*}\n",
    "\\tilde{p}(y=c) & = e^{\\boldsymbol{\\theta}^{(c)\\top} \\mathbf{x}} \\ \\ \\ \\ \\ c \\in \\{1, 2,..., C\\} \\newline\n",
    "{p}(y=c) & = \\frac{e^{\\boldsymbol{\\theta}^{(c)\\top} \\mathbf{x}}}{\\sum_{c^\\prime=1}^{C} e^{\\boldsymbol{\\theta}^{(c^\\prime)\\top} \\mathbf{x}}} \\ \\ \\ \\ \\ c \\in \\{1, 2,..., C\\}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Wikipedia contributors. (2020, March 31). Likelihood function. In Wikipedia, The Free Encyclopedia. Retrieved 14:56, April 3, 2020, from https://en.wikipedia.org/w/index.php?title=Likelihood_function&oldid=948338993\n",
    "\n",
    "Wikipedia contributors. (2020, March 4). Maximum likelihood estimation. In Wikipedia, The Free Encyclopedia. Retrieved 14:57, April 3, 2020, from https://en.wikipedia.org/w/index.php?title=Maximum_likelihood_estimation&oldid=943960597\n",
    "\n",
    "\n",
    "Wikipedia contributors. (2020, March 27). Entropy (information theory). In Wikipedia, The Free Encyclopedia. Retrieved 14:54, April 3, 2020, from https://en.wikipedia.org/w/index.php?title=Entropy_(information_theory)&oldid=947602458\n",
    "\n",
    "\n",
    "Wikipedia contributors. (2020, March 12). Cross entropy. In Wikipedia, The Free Encyclopedia. Retrieved 14:53, April 3, 2020, from https://en.wikipedia.org/w/index.php?title=Cross_entropy&oldid=945192009\n",
    "\n",
    "Ian Goodfellow, Yoshua Bengio, and Aaron Courville. 2016. Deep Learning. The MIT Press."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
