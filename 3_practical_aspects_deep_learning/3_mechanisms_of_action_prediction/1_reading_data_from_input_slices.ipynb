{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from  IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data using pandas and transforming to tf Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 876\n",
      "Number of targets: 207\n"
     ]
    }
   ],
   "source": [
    "features = pd.read_csv(\"data/train_features.csv\")\n",
    "targets = pd.read_csv(\"data/train_targets_scored.csv\")\n",
    "\n",
    "cols_features = features.columns\n",
    "cols_targets = targets.columns\n",
    "\n",
    "num_features = len(cols_features)\n",
    "num_targets = len(cols_targets)\n",
    "\n",
    "print(\"Number of features:\" , num_features)\n",
    "print(\"Number of targets:\" , num_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19051 train examples\n",
      "4763 val examples\n"
     ]
    }
   ],
   "source": [
    "# add label to dataset \n",
    "df = features.copy()\n",
    "targets.pop(\"sig_id\")\n",
    "df[\"label\"] = pd.Series(pd.Series(targets.values.tolist()))\n",
    "\n",
    "# split data\n",
    "train, val = train_test_split(df, test_size=0.2)\n",
    "\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'val examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "    \n",
    "    dataframe = dataframe.copy()\n",
    "    dataframe.pop('sig_id')\n",
    "    labels = dataframe.pop('label')\n",
    "\n",
    "    # stack multi label target\n",
    "    labels = [tf.stack(label) for label in labels]\n",
    "    \n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(features))\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = df_to_dataset(train, batch_size=BATCH_SIZE)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 features: ['cp_type', 'cp_time', 'cp_dose', 'g-0', 'g-1']\n",
      "A batch of cp_types: [b'trt_cp' b'trt_cp' b'trt_cp' b'ctl_vehicle' b'ctl_vehicle' b'trt_cp'\n",
      " b'trt_cp' b'trt_cp' b'trt_cp' b'trt_cp' b'trt_cp' b'ctl_vehicle'\n",
      " b'trt_cp' b'trt_cp' b'trt_cp' b'trt_cp' b'trt_cp' b'trt_cp' b'trt_cp'\n",
      " b'trt_cp' b'trt_cp' b'trt_cp' b'trt_cp' b'trt_cp' b'trt_cp' b'trt_cp'\n",
      " b'trt_cp' b'trt_cp' b'trt_cp' b'trt_cp' b'trt_cp' b'ctl_vehicle']\n",
      "A batch of cp_doses: [b'D1' b'D2' b'D1' b'D1' b'D1' b'D1' b'D2' b'D2' b'D2' b'D1' b'D2' b'D1'\n",
      " b'D1' b'D1' b'D1' b'D2' b'D2' b'D1' b'D1' b'D1' b'D2' b'D2' b'D1' b'D2'\n",
      " b'D1' b'D1' b'D2' b'D1' b'D1' b'D1' b'D1' b'D2']\n",
      "A batch of cp_times: [72 48 48 48 72 48 24 24 48 72 24 24 48 72 24 48 48 24 24 24 24 24 48 24\n",
      " 72 48 72 24 72 48 48 48]\n",
      "A batch of g-0: [-0.1264 -0.6446 -0.2149 -0.1447  0.5396  0.0439 -0.8981 -1.004   0.3372\n",
      "  3.215  -0.0893 -0.4287 -0.0626 -0.005   0.0222 -0.0978 -0.5466  1.227\n",
      " -1.026  -0.0915 -1.415  -0.1153  0.934   0.3422 -0.6679 -0.524   1.435\n",
      "  0.2691  1.343  -0.6191 -1.097  -0.2429]\n",
      "A batch of targets: [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "for feature_batch, label_batch in train_ds.take(1):\n",
    "    print('First 5 features:', list(feature_batch.keys())[:5])\n",
    "    print('A batch of cp_types:', feature_batch['cp_type'].numpy())\n",
    "    print('A batch of cp_doses:', feature_batch['cp_dose'].numpy())\n",
    "    print('A batch of cp_times:', feature_batch['cp_time'].numpy())\n",
    "    print('A batch of g-0:', feature_batch['g-0'].numpy())\n",
    "    \n",
    "    \n",
    "    print('A batch of targets:', label_batch.numpy()) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlcourse-venv",
   "language": "python",
   "name": "dlcourse-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
